#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""

"""

import csv
import datetime as dt
import json as js
import logging as log
import random
import re
import sys
from pathlib import Path
from typing import Any, Dict

import numpy as np
from catboost import CatBoostRegressor
from joblib import dump
from lightgbm import LGBMRegressor
from sklearn.base import BaseEstimator
from sklearn.cross_decomposition import PLSRegression
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, WhiteKernel
from sklearn.linear_model import ElasticNet, Lasso, Ridge
from sklearn.metrics import r2_score
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor


class AutoDataModelTrainerCore:
    """

    """

    def __init__(self):
        """

        """
        # åˆå§‹åŒ–åŸºç¡€è·¯å¾„ï¼ˆè·å–é¡¹ç›®æ ¹ç›®å½•çš„çˆ¶çº§ç›®å½•ï¼‰
        self.base_path = Path(sys.argv[0]).resolve().parent.parent
        # æ£€æŸ¥ç‚¹å­˜å‚¨è·¯å¾„ï¼ˆä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹ï¼‰
        self.ckpt_path = Path(self.base_path, "ckpt")
        # åŸå§‹æ•°æ®å­˜å‚¨è·¯å¾„ï¼ˆå­˜æ”¾è¾“å…¥æ•°æ®æ–‡ä»¶ï¼‰
        self.data_path = Path(self.base_path, "data")
        # æ—¥å¿—æ–‡ä»¶å­˜å‚¨è·¯å¾„ï¼ˆå­˜æ”¾ç³»ç»Ÿè¿è¡Œæ—¥å¿—ï¼‰
        self.logs_path = Path(self.base_path, "logs")
        # æ¨¡å—ä»£ç å­˜å‚¨è·¯å¾„ï¼ˆå­˜æ”¾åŠŸèƒ½æ¨¡å—æ–‡ä»¶ï¼‰
        self.mode_path = Path(self.base_path, "mode")
        # ç»“æœæ–‡ä»¶å­˜å‚¨è·¯å¾„ï¼ˆå­˜æ”¾è®¡ç®—ç»“æœæ•°æ®ï¼‰
        self.rezu_path = Path(self.base_path, "results")
        # é…ç½®æ–‡ä»¶å­˜å‚¨è·¯å¾„ï¼ˆå­˜æ”¾å‚æ•°é…ç½®æ–‡ä»¶ï¼‰
        self.sets_path = Path(self.base_path, "sets")
        # åˆå§‹åŒ–æ—¥å¿—ç®¡ç†ç³»ç»Ÿ
        self.root_logg = self._init_logger_manager()
        # åˆ›å»ºå¿…è¦ç›®å½•ç»“æ„
        self._init_directories()
        # æ¨¡å‹æ³¨å†Œè¡¨é…ç½®æ–‡ä»¶å
        self.name_regi = "sets_mode_regi.json"
        # åŠ è½½æ¨¡å‹æ³¨å†Œè¡¨é…ç½®
        self.regi_mode = self._init_model_registry()
        # å•æ¨¡å‹æœ€å¤§è®­ç»ƒå°è¯•æ¬¡æ•°
        self.retr_maxm = 3

    def _init_directories(self):
        """
        åˆå§‹åŒ–æ‰€éœ€çš„ç›®å½•ç»“æ„ã€‚
        è¯¥æ–¹æ³•å®šä¹‰äº†ä¸€ç»„å¿…è¦çš„æ–‡ä»¶è·¯å¾„ï¼Œå¹¶æ£€æŸ¥è¿™äº›è·¯å¾„æ˜¯å¦å­˜åœ¨ã€‚å¦‚æœè·¯å¾„ä¸å­˜åœ¨ï¼Œ
        åˆ™åˆ›å»ºå¯¹åº”çš„ç›®å½•å¹¶è®°å½•ç›¸å…³ä¿¡æ¯åˆ°æ—¥å¿—å’Œæ§åˆ¶å°è¾“å‡ºä¸­ã€‚
        Initialize the required directory structure. This method defines a set of necessary file paths,
        checks whether these paths exist, creates corresponding directories if they are missing, and logs
        relevant information to both the console output and log files.
        :param: None
        :return: None
        :raises: None
        """
        # ç›®å½•é…ç½®å­—å…¸ï¼ˆè·¯å¾„å¯¹è±¡: ç›®å½•æè¿°ï¼‰
        dict_reqs_dirs = {
            self.ckpt_path: "æ¨¡å‹æ£€æŸ¥ç‚¹ç›®å½•",
            self.data_path: "åŸå§‹æ•°æ®ç›®å½•",
            self.logs_path: "ç³»ç»Ÿæ—¥å¿—ç›®å½•",
            self.mode_path: "åŠŸèƒ½æ¨¡å—ç›®å½•",
            self.rezu_path: "è®¡ç®—ç»“æœç›®å½•",
            self.sets_path: "é…ç½®è®¾ç½®ç›®å½•"
            }
        # éå†å­—å…¸ä¸­çš„æ¯ä¸ªè·¯å¾„åŠå…¶æè¿°ä¿¡æ¯
        for full_path, desc_info in dict_reqs_dirs.items():
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not full_path.exists():
                # å¦‚æœè·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºè¯¥è·¯å¾„
                full_path.mkdir()
                # è®°å½•æ—¥å¿—
                self.root_logg.info(f"âœ… {desc_info}ï¼š{full_path}ï¼Œæ–‡ä»¶è·¯å¾„å·²åˆ›å»ºã€‚")
                # æ§åˆ¶å°è¾“å‡º
                print(f"âœ… {desc_info}ï¼š{full_path}ï¼Œæ–‡ä»¶è·¯å¾„å·²åˆ›å»ºã€‚")

    def _init_logger_manager(self):
        """
        ä¸ºç±»å®ä¾‹åˆå§‹åŒ–æ—¥å¿—ç®¡ç†å™¨ã€‚
        è¯¥æ–¹æ³•æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼šé…ç½®åä¸º'ADModelTrainerCore'çš„æ—¥å¿—è®°å½•å™¨ï¼›è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºINFOï¼›ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨ï¼›
        åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ–‡ä»¶ï¼›å®šä¹‰æ—¥å¿—æ¶ˆæ¯æ ¼å¼ï¼›å¹¶åœ¨æ–‡ä»¶å¤„ç†å™¨ä¸å­˜åœ¨æ—¶å‘æ—¥å¿—è®°å½•å™¨æ·»åŠ FileHandlerã€‚
        Initializes the logger manager for the class instance.
        This method configures a logger with the name "ADModelTrainerCore", sets its logging level to INFO,
        ensures the existence of the log directory, and creates a timestamped log file. It also defines
        the log message format and adds a FileHandler to the logger if one does not already exist.
        :param: None
        :return: None
        :raises: None
        """
        # åˆ›å»ºæ—¥å¿—è®°å½•å™¨å®ä¾‹
        self.root_logg = log.getLogger("ADModelTrainerCore")
        # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºINFO
        self.root_logg.setLevel(log.INFO)
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        self.logs_path.mkdir(exist_ok=True)
        # æ ¼å¼åŒ–å½“å‰æ—¶é—´ä¸ºæŒ‡å®šæ ¼å¼å­—ç¬¦ä¸²
        stri_time = dt.datetime.now().strftime("%Y_%m%d_%H%M_00%S")
        # å®šä¹‰æ—¥å¿—æ–‡ä»¶å
        logs_name = f"Tran_Logs_{stri_time}.log"
        # å®šä¹‰æ—¥å¿—æ¶ˆæ¯çš„æ ¼å¼
        logs_fmts = log.Formatter("[%(asctime)s] %(levelname)s - %(message)s", datefmt="%Y-%m-%d_%H:%M:%S")
        # æ„é€ æ—¥å¿—æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        path_logs = Path(self.logs_path, logs_name)
        # åˆ›å»ºä¸€ä¸ªå¯¹è±¡ç”¨äºå†™å…¥æ—¥å¿—æ–‡ä»¶
        objt_logs_hand = log.FileHandler(path_logs, encoding="utf-8")
        # ä¸ºæ—¥å¿—å¯¹è±¡è®¾ç½®æ—¥å¿—è®°å½•æ ¼å¼
        objt_logs_hand.setFormatter(logs_fmts)
        # é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨ï¼ˆæ£€æŸ¥ç°æœ‰å¤„ç†å™¨ç±»å‹ï¼‰
        if not any(isinstance(h, log.FileHandler) for h in self.root_logg.handlers):
            # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™æ·»åŠ æ–‡ä»¶å¤„ç†å™¨
            self.root_logg.addHandler(objt_logs_hand)
        # è®°å½•åˆå§‹åŒ–å®Œæˆæ—¥å¿—
        self.root_logg.info("âœ… æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆã€‚")
        return self.root_logg

    def _init_model_registry(self) -> Dict[str, dict]:
        """
        åˆå§‹åŒ–æ¨¡å‹æ³¨å†Œè¡¨ï¼ŒåŠ è½½æ³¨å†Œè¡¨æ–‡ä»¶å¹¶æ„å»ºæ¨¡å‹çš„åˆå§‹åŒ–å‡½æ•°ä¸å‚æ•°é…ç½®çš„æ˜ å°„å…³ç³»ã€‚
        æ­¤æ–¹æ³•é¦–å…ˆæ£€æŸ¥æ³¨å†Œè¡¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è®°å½•è­¦å‘Šæ—¥å¿—å¹¶æŠ›å‡ºå¼‚å¸¸ã€‚å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œåˆ™è§£æå…¶å†…å®¹å¹¶éå†æ¯ä¸ªæ¨¡å‹é…ç½®ï¼ŒéªŒè¯åˆå§‹åŒ–å‡½æ•°æ˜¯å¦å­˜åœ¨ï¼Œ
        å¹¶å°†æ¨¡å‹åç§°ä¸å…¶å¯¹åº”çš„åˆå§‹åŒ–å‡½æ•°å’Œå‚æ•°é…ç½®å­˜å…¥å­—å…¸ä¸­ã€‚æœ€åè¿”å›è¯¥å­—å…¸ã€‚
        æŠ›å‡ºé”™è¯¯ï¼šFileNotFoundError: å¦‚æœæ³¨å†Œè¡¨æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸
        æŠ›å‡ºé”™è¯¯ï¼šException: å¦‚æœæŸä¸ªæ¨¡å‹çš„åˆå§‹åŒ–å‡½æ•°æœªæ‰¾åˆ°ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸
        è¿”å›ï¼šåŒ…å«æ¨¡å‹åç§°ä¸å¯¹åº”åˆå§‹åŒ–å‡½æ•°åŠå‚æ•°é…ç½®çš„å­—å…¸ï¼Œ
             é”®ä¸ºæ¨¡å‹åç§°ï¼Œå€¼ä¸ºå…ƒç»„ (åˆå§‹åŒ–å‡½æ•°, å‚æ•°é…ç½®)
        Initialize the model registry, load the registry file, and build a mapping between the model's initialization 
        function and parameter configuration.
        this method first checks if the registry file exists. if it does not exist, it logs a warning and throws an
        exception. if the file exists, it parses its content and iterates through each model configuration to verify whether
        the initialization function exists. it then stores the model name along with its corresponding initialization
        function and parameter configuration into a dictionary. finally, it returns this dictionary.
        :param: none.
        :raises FileNotFoundError: thrown if the registry file is not found.
        :raises Exception: thrown if an initialization function for a certain model is not found.
        :return: dict[str, tuple[callable, dict]]
                 A dictionary containing the model name as the key and a tuple of (initialization function,
                 parameter configuration) as the value.
        :rtype: dict[str, tuple[callable, dict]]
        """
        # æ„é€ æ³¨å†Œè¡¨æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        regi_path = Path(self.sets_path, self.name_regi)
        # æ£€æŸ¥æ³¨å†Œè¡¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not regi_path.exists():
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè®°å½•è­¦å‘Šæ—¥å¿—
            self.root_logg.error(f"â— æ³¨å†Œè¡¨æ–‡ä»¶ç¼ºå¤±ï¼š{self.name_regi}")
            # æŠ›å‡ºé”™è¯¯ä»£ç 
            raise FileNotFoundError(f"â— æ¨¡å‹æ³¨å†Œè¡¨æ–‡ä»¶ {self.name_regi} æœªæ‰¾åˆ°")
        # æ‰“å¼€æ³¨å†Œè¡¨æ–‡ä»¶å¹¶åŠ è½½å…¶å†…å®¹
        with open(regi_path, "r", encoding="utf-8") as regi_file:
            # ä½¿ç”¨jsonæ¨¡å—åŠ è½½æ–‡ä»¶å†…å®¹
            regi_data = js.load(regi_file)
        # åˆå§‹åŒ–æ³¨å†Œå­—å…¸
        dict_mode_regi = {}
        # åŠ è½½æ¨¡å‹åç§°ä¸é…ç½®
        for mode_name, conf_mode in regi_data.items():
            # è·å–æ¨¡å‹å‡½æ•°åç§°
            init_func_name = conf_mode.get("init_func")
            # è·å–æ¨¡å‹å‚æ•°é…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            init_func_conf = conf_mode.get("para_conf", {})
            # åˆ¤æ–­å‡½æ•°æ˜¯å¦å­˜åœ¨
            if not hasattr(self, init_func_name):
                # è®°å½•é”™è¯¯ä¿¡æ¯
                self.root_logg.error(f"âŒ åˆå§‹åŒ–å‡½æ•°ç¼ºå¤±ï¼š{init_func_name}")
                # æŠ›å‡ºé”™è¯¯ä»£ç 
                raise AttributeError(f"âŒ æ¨¡å‹ {init_func_name} åˆå§‹åŒ–å‡½æ•°æœªæ‰¾åˆ°")
            # é…ç½®æ¨¡å‹å‡½æ•°
            init_func = getattr(self, init_func_name)
            # å°†ç»“æœå­˜å…¥æ³¨å†Œå­—å…¸ä¸­
            dict_mode_regi[mode_name] = (init_func, init_func_conf)
        return dict_mode_regi

    def _init_simple_fit_model(self, **para_mode) -> BaseEstimator:
        """
        Initialize and return the specified machine learning model object.
        This method selects and instantiates the corresponding model object from a predefined model dictionary based on the
        provided model name and parameters. If the provided model name is not in the list of supported models, an error log
        is recorded and an exception is raised. After successful initialization, a log message is recorded, and a message
        indicating that the model has been loaded is printed.
        :param para_mode: A dictionary containing the model name and initialization parameters.
                          Must contain the key "mode_name", whose value is a string representing the model name.
                          The remaining key-value pairs will be passed as parameters for model initialization.
        :return: An instantiated machine learning model object, belonging to the BaseEstimator class or its subclass.
        :raises ValueError: If the provided model name is not in the list of supported models, this exception is raised.

        åˆå§‹åŒ–å¹¶è¿”å›æŒ‡å®šçš„æœºå™¨å­¦ä¹ æ¨¡å‹å¯¹è±¡ã€‚
        æ­¤æ–¹æ³•æ ¹æ®æä¾›çš„æ¨¡å‹åç§°å’Œå‚æ•°ï¼Œä»é¢„å®šä¹‰çš„æ¨¡å‹å­—å…¸ä¸­é€‰æ‹©å¹¶å®ä¾‹åŒ–å¯¹åº”çš„æ¨¡å‹å¯¹è±¡ã€‚å¦‚æœæä¾›çš„æ¨¡å‹åç§°ä¸åœ¨æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨ä¸­ï¼Œåˆ™è®°å½•é”™è¯¯æ—¥å¿—å¹¶æŠ›å‡ºå¼‚å¸¸ã€‚
        æˆåŠŸåˆå§‹åŒ–åï¼Œä¼šè®°å½•æ—¥å¿—ä¿¡æ¯å¹¶æ‰“å°æ¨¡å‹åŠ è½½å®Œæˆçš„æ¶ˆæ¯ã€‚
        :param para_mode: åŒ…å«æ¨¡å‹åç§°å’Œåˆå§‹åŒ–å‚æ•°çš„å­—å…¸ã€‚
                          å¿…é¡»åŒ…å«é”® "mode_name"ï¼Œå…¶å€¼ä¸ºå­—ç¬¦ä¸²ç±»å‹ï¼Œè¡¨ç¤ºæ¨¡å‹åç§°ã€‚
                          å…¶ä½™é”®å€¼å¯¹å°†ä½œä¸ºæ¨¡å‹åˆå§‹åŒ–çš„å‚æ•°ä¼ é€’ã€‚
        :return: å®ä¾‹åŒ–çš„æœºå™¨å­¦ä¹ æ¨¡å‹å¯¹è±¡ï¼Œå±äº BaseEstimator ç±»æˆ–å…¶å­ç±»ã€‚
        :raises ValueError: å¦‚æœæä¾›çš„æ¨¡å‹åç§°ä¸åœ¨æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨ä¸­ï¼Œåˆ™æŠ›å‡ºæ­¤å¼‚å¸¸ã€‚
        """
        mode_name = para_mode.pop("mode_name")  # ä»å‚æ•°å­—å…¸ä¸­ç§»é™¤å¹¶è·å–é”®ä¸º"mode_name"çš„å€¼ï¼Œè¯¥å€¼ä»£è¡¨æ¨¡å‹åç§°
        # å®šä¹‰æ¨¡å‹å­—å…¸
        dict_mode = {
            "Ridge": Ridge,  # å°†å­—ç¬¦ä¸²"Ridge"æ˜ å°„åˆ°Ridgeç±»
            "Lasso": Lasso,  # å°†å­—ç¬¦ä¸²"Lasso"æ˜ å°„åˆ°Lassoç±»
            "ElasticNet": ElasticNet,  # å°†å­—ç¬¦ä¸²"ElasticNet"æ˜ å°„åˆ°ElasticNetç±»
            "PLSReg": PLSRegression,  # å°†å­—ç¬¦ä¸²"PLSReg"æ˜ å°„åˆ°PLSRegressionç±»
            "XGBoostReg": XGBRegressor,  # å°†å­—ç¬¦ä¸²"XGBoostReg"æ˜ å°„åˆ°XGBRegressorç±»
            "LightGBMReg": LGBMRegressor,  # å°†å­—ç¬¦ä¸²"LightGBMReg"æ˜ å°„åˆ°LGBMRegressorç±»
            "CatBoostReg": CatBoostRegressor,  # å°†å­—ç¬¦ä¸²"CatBoostReg"æ˜ å°„åˆ°CatBoostRegressorç±»
            "MLPRegressor": MLPRegressor,  # å°†å­—ç¬¦ä¸²"MLPRegressor"æ˜ å°„åˆ°MLPRegressorç±»
            "KNNReg": KNeighborsRegressor  # å°†å­—ç¬¦ä¸²"KNNReg"æ˜ å°„åˆ°KNeighborsRegressorç±»
            }
        if mode_name not in dict_mode:  # æ£€æŸ¥æä¾›çš„æ¨¡å‹åç§°æ˜¯å¦ä¸åœ¨æ”¯æŒçš„æ¨¡å‹å­—å…¸ä¸­
            self.root_logg.error(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹ï¼š{mode_name}ã€‚")  # å¦‚æœæ¨¡å‹ä¸è¢«æ”¯æŒï¼Œè®°å½•é”™è¯¯æ—¥å¿—ä¿¡æ¯
            raise ValueError(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹ï¼š{mode_name}ã€‚")  # æŠ›å‡ºä¸€ä¸ªValueErrorå¼‚å¸¸ï¼Œæç¤ºæ¨¡å‹ä¸è¢«æ”¯æŒ
        mode_objt = dict_mode[mode_name](**para_mode)  # ä½¿ç”¨æä¾›çš„å‚æ•°å®ä¾‹åŒ–å¯¹åº”çš„æ¨¡å‹å¯¹è±¡
        self.root_logg.info(f"âœ… æ¨¡å‹ï¼š{mode_name}ï¼Œå·²åˆå§‹åŒ–å®Œæˆã€‚")  # è®°å½•æ¨¡å‹åˆå§‹åŒ–ä¿¡æ¯
        print(f"âœ… æ¨¡å‹ï¼š{mode_name}æˆåŠŸè½½å…¥ï¼Œå‡†å¤‡å¼€å§‹è®­ç»ƒã€‚")  # åœ¨æ§åˆ¶å°æ‰“å°å¼€å§‹è®­ç»ƒä¿¡æ¯
        return mode_objt

    def _init_svm_model(self, **para_mode) -> BaseEstimator:
        """"""
        mode_name = para_mode.pop("mode_name")
        vali_kern = ["rbf", "poly"]
        kern_type = para_mode.get("kernel", "")
        if kern_type not in vali_kern:
            self.root_logg.error(f"âŒ ä¸æ”¯æŒçš„SVRæ ¸ç±»å‹ï¼š{kern_type}ã€‚")
            raise ValueError(f"âŒ SVRæ¨¡å‹ {mode_name} é…ç½®é”™è¯¯ï¼šæ— æ•ˆæ ¸ç±»å‹")
        else:
            self.root_logg.info(f"âœ… æ¨¡å‹ï¼š{mode_name}ï¼Œå·²åˆå§‹åŒ–å®Œæˆã€‚")
            print(f"âœ… æ¨¡å‹ï¼š{mode_name}æˆåŠŸè½½å…¥ï¼Œå‡†å¤‡å¼€å§‹è®­ç»ƒã€‚")
        mode_objt = SVR(**para_mode)
        return mode_objt

    def _init_gp_model(self, **para_mode) -> BaseEstimator:
        """"""
        mode_name = para_mode.pop("mode_name")
        kern_sets = para_mode.pop("kernel", {})
        base_kern = para_mode.pop("base_kernel", "RBF")
        kern_type = {
            "RBF": RBF(length_scale=kern_sets.get("length_scale", 1.0)),
            "WhiteKernel": WhiteKernel(noise_level=kern_sets.get("noise_level", 1.0)),
            }.get(base_kern, RBF())
        mode_objt = GaussianProcessRegressor(kern_type, **para_mode)
        self.root_logg.info(f"âœ… æ¨¡å‹ï¼š{mode_name}ï¼Œå·²åˆå§‹åŒ–å®Œæˆã€‚")
        print(f"âœ… æ¨¡å‹ï¼š{mode_name}æˆåŠŸè½½å…¥ï¼Œå‡†å¤‡å¼€å§‹è®­ç»ƒã€‚")
        return mode_objt

    def _train_single_model(self, mode_name: str, dict_spli: Dict[str, Any]) -> Dict[str, Any]:
        self.root_logg.info(f"â–¶ å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼š{mode_name}")
        if mode_name not in self.regi_mode:
            self.root_logg.error(f"âŒ æœªæ³¨å†Œçš„æ¨¡å‹ï¼š{mode_name}")
            raise KeyError(f"âŒ æœªæ³¨å†Œçš„æ¨¡å‹ï¼š{mode_name}")
            # æ•°æ®æ ‡å‡†åŒ–æå–
        x_train, y_train = dict_spli["tran_sets"]
        x_test, y_test = dict_spli["test_sets"]
        func_init, para_conf = self.regi_mode[mode_name]
        dict_resu = {
            "stts_train": "æœªè¾¾æ ‡",
            "best_r2": -np.inf,
            "n_retry": 0,
            "path_ckpt": None
            }
        para_tran = {'mode_name': mode_name, **para_conf}
        best_model = None
        for vari_atte in range(1, self.retr_maxm + 1):
            try:
                self.root_logg.info(f"ğŸ”„ å°è¯•ç¬¬ {vari_atte}/{self.retr_maxm} æ¬¡è®­ç»ƒ")
                print(f"æ­£åœ¨å°è¯• {mode_name} ç¬¬ {vari_atte} æ¬¡è®­ç»ƒ...")
                # æ¨¡å‹åˆå§‹åŒ–
                objt_mode = func_init(**para_tran)
                objt_mode.fit(x_train, y_train)
                # æ€§èƒ½è¯„ä¼°
                y_pred = objt_mode.predict(x_test)
                current_r2 = r2_score(y_test, y_pred)
                # æ›´æ–°æœ€ä½³ç»“æœ
                if current_r2 > dict_resu['best_r2']:
                    best_model = objt_mode
                    dict_resu.update(
                            {
                                'best_r2': current_r2,
                                'n_retry': vari_atte
                                }
                            )
                    self.root_logg.info(f"ğŸ“ˆ æ›´æ–°æœ€ä½³RÂ²å€¼ï¼š{current_r2:.6f}")
                    # è¾¾æ ‡æ£€æŸ¥
                if current_r2 >= 0.75:
                    dict_resu['stts_train'] = 'è¾¾æ ‡'
                    self.root_logg.info(f"âœ… ç¬¬ {vari_atte} æ¬¡å°è¯•è¾¾æ ‡")
                    break
            except Exception as e:
                error_msg = f"âŒ ç¬¬ {vari_atte} æ¬¡è®­ç»ƒå¤±è´¥ï¼š{str(e)}"
                self.root_logg.error(error_msg)
                print(error_msg)
                # æ¨¡å‹æŒä¹…åŒ–
        if best_model and dict_resu['best_r2'] > -np.inf:
            stri_time = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
            file_name = f"{mode_name}_{stri_time}.joblib"
            path_ckpt = Path(self.ckpt_path, file_name)
            try:
                dump(best_model, path_ckpt)
                dict_resu['path_ckpt'] = str(path_ckpt)
                self.root_logg.info(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜è‡³ï¼š{path_ckpt}")
            except Exception as e:
                error_msg = f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥ï¼š{str(e)}"
                self.root_logg.error(error_msg)
                print(error_msg)
                # è®­ç»ƒç»“æœè®°å½•
        self.root_logg.info(
                f"â–· è®­ç»ƒå®Œæˆï¼š{mode_name} | çŠ¶æ€ï¼š{dict_resu['stts_train']} | "
                f"æœ€ä½³RÂ²ï¼š{dict_resu['best_r2']:.4f} | å°è¯•æ¬¡æ•°ï¼š{dict_resu['n_retry']}"
                )

        return dict_resu

    def run(self):
        spli_data = DataPreprocessing().run()
        for func_name in spli_data.keys():
            func_data = spli_data[func_name]
            for mode_name in self.regi_mode.keys():
                self._train_single_model(mode_name, func_data)


class DataPreprocessing:
    def __init__(self):
        """

        """

        self.base_path = AutoDataModelTrainerCore().base_path
        self.data_path = AutoDataModelTrainerCore().rezu_path
        self.sets_path = AutoDataModelTrainerCore().sets_path
        self.band_name = "sets_band_wave.json"
        self.refl_name = "rezu_spad_refl.csv"
        self.func_name = "sets_data_func.json"
        self.root_logg = AutoDataModelTrainerCore().root_logg
        self.dict_refl = self._init_reflectance_csv()
        self.band_wave = self._init_gain_wave_band()
        self.tran_rati = 0.8
        self.vali_rati = 0.1
        self.test_rati = 0.1
        self.spli_dids = self._init_random_dataset_selector()
        self.func_data = self._init_fetch_formula_config()

    def _init_random_dataset_selector(self):
        """

        """
        data_sids = list(range(1, 241))
        random.shuffle(data_sids)
        tran_size = int(self.tran_rati * len(data_sids))
        vali_size = int(self.vali_rati * len(data_sids))
        test_size = int(self.test_rati * len(data_sids))
        list_tran = data_sids[:tran_size]
        list_vali = data_sids[tran_size:(tran_size + vali_size)]
        list_test = data_sids[test_size:]
        dict_spli = {
            "tran_sets": list_tran,
            "vali_sets": list_vali,
            "test_sets": list_test
            }
        return dict_spli

    def _init_gain_wave_band(self):
        """

        """
        band_path = Path(self.sets_path, self.band_name)
        if not band_path.exists():
            self.root_logg.error(f"æ³¢æ®µé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{band_path.name}ã€‚")
            raise FileNotFoundError(f"æ³¢æ®µé…ç½®æ–‡ä»¶ç¼ºå¤±ï¼š{band_path.name}ã€‚")
        with open(band_path, "r") as band_file:
            band_data = js.load(band_file)
        self.root_logg.info("æ³¢æ®µé…ç½®æ–‡ä»¶æ­£å¸¸è¯»å–")
        dict_band_wave = band_data.get("band_wave", {})
        return dict_band_wave

    def find_closest_band(self, targ_wave: float, thre_shol: float = 5.0) -> int:
        """

        """
        if targ_wave <= 0:
            self.root_logg.error(f"ç›®æ ‡æ³¢é•¿{targ_wave}å¿…é¡»ä¸ºæ­£æ•°ã€‚")
            raise ValueError("ç›®æ ‡æ³¢é•¿å¿…é¡»ä¸ºæ­£æ•°")
        if thre_shol <= 0:
            self.root_logg.error(f"ç›®æ ‡æ³¢é•¿{thre_shol}å¿…é¡»ä¸ºæ­£æ•°")
            raise ValueError("é˜ˆå€¼å¿…é¡»ä¸ºæ­£æ•°")
        clos_band = None
        mini_diff = float('inf')
        # éå†æ³¢æ®µå­—å…¸ï¼Œå¯»æ‰¾æœ€æ¥è¿‘çš„æ³¢æ®µ
        for band_numb, wave_lent in self.band_wave.items():
            diff_lent = abs(wave_lent - targ_wave)
            if diff_lent < mini_diff:
                mini_diff = diff_lent
                clos_band = band_numb
        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°æœ‰æ•ˆæ³¢æ®µ
        if clos_band is None:
            raise ValueError("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ³¢æ®µ")
        # å¦‚æœæœ€å°å·®å€¼è¶…è¿‡é˜ˆå€¼ï¼Œè®°å½•æ—¥å¿—
        if mini_diff > thre_shol:
            self.root_logg.warning(
                    f"ç›®æ ‡æ³¢é•¿ï¼š{targ_wave:.3f}nm çš„æœ€æ¥è¿‘æ³¢æ®µ {clos_band} "
                    f"({self.band_wave[clos_band]:.3f}nm) çš„æ³¢é•¿å·®ä¸º {mini_diff:.3f}nmï¼Œè¶…è¿‡é™åº¦ã€‚"
                    )
        return clos_band

    def create_index_function(self, func_stri):
        """

        """
        list_wave = {float(wave_leng) for wave_leng in re.findall(r'@(\d+\.?\d*)', func_stri)}
        replacements = {f'@{int(wave_leng)}': f"reflectance['{self.find_closest_band(wave_leng)}']"
                        for wave_leng in list_wave}
        stri_expr = func_stri
        for stri_part, stri_repl in replacements.items():
            stri_expr = stri_expr.replace(stri_part, stri_repl)
        return lambda func_refl: eval(
                stri_expr,
                {'__builtins__': None},
                {'reflectance': func_refl}
                )

    def _init_reflectance_csv(self):
        """

        """
        need_floa = {"SPAD"} | {f"Band_{numb_rows}" for numb_rows in range(1, 205)}
        refl_path = Path(self.data_path, self.refl_name)
        if not refl_path.exists():
            raise FileNotFoundError(f"åå°„ç‡æ–‡ä»¶ç¼ºå¤±ï¼š{refl_path}ã€‚")
        with open(refl_path, "r") as refl_file:
            data_read = csv.DictReader(refl_file)
            refl_data = {}
            for row in data_read:
                conv_rows = {}
                for band_keys, band_valu in row.items():
                    if band_keys in need_floa:
                        try:
                            # å°è¯•å°†æ•°å€¼å­—æ®µè½¬æ¢ä¸ºæµ®ç‚¹æ•°
                            conv_rows[band_keys] = float(band_valu)
                        except ValueError:
                            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè®°å½•è­¦å‘Šæ—¥å¿—å¹¶è®¾ç½®ä¸º None
                            self.root_logg.warning(
                                    f"å­—æ®µ {band_keys} çš„å€¼ {band_valu} æ— æ³•è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼Œè®¾ç½®ä¸º None"
                                    )
                            conv_rows[band_keys] = None
                    else:
                        # éæ•°å€¼å­—æ®µä¿æŒåŸå§‹å€¼
                        conv_rows[band_keys] = band_valu
                # ä½¿ç”¨ ID ä½œä¸ºé”®å­˜å‚¨è½¬æ¢åçš„è¡Œ
                refl_data[conv_rows["ID"]] = conv_rows
        return refl_data

    def _init_fetch_formula_config(self):
        """

        """
        func_path = Path(self.sets_path, self.func_name)
        with open(func_path, "r", encoding="utf-8") as func_file:
            func_json = js.load(func_file)
        dict_func_sets = func_json["func_list"]
        return dict_func_sets

    def create_data_splits(self, func_data):
        dict_spli_data = {}
        tran_lisx = []
        tran_lisy = []
        vali_lisx = []
        vali_lisy = []
        test_lisx = []
        test_lisy = []
        for tran_cunt in self.spli_dids["tran_sets"]:
            tran_lisx.append([func_data[str(tran_cunt)]["comp_datx"], 1])
            tran_lisy.append(func_data[str(tran_cunt)]["comp_daty"])
        dict_spli_data["tran_sets"] = tran_lisx, tran_lisy
        for vali_cunt in self.spli_dids["vali_sets"]:
            vali_lisx.append([func_data[str(vali_cunt)]["comp_datx"], 1])
            vali_lisy.append(func_data[str(vali_cunt)]["comp_daty"])
        dict_spli_data["vali_sets"] = vali_lisx, vali_lisy
        for test_cunt in self.spli_dids["test_sets"]:
            test_lisx.append([func_data[str(test_cunt)]["comp_datx"], 1])
            test_lisy.append(func_data[str(test_cunt)]["comp_daty"])
        dict_spli_data["test_sets"] = test_lisx, test_lisy
        return dict_spli_data

    def compute_singel_vegetation_indices(self, func_name):
        stri_func = self.func_data[func_name]
        func_objt = self.create_index_function(stri_func)
        keyw_data = {}
        for coun_grop in range(1, 241):
            sign_refl = self.dict_refl[str(coun_grop)]
            func_rezu = func_objt(sign_refl)
            comp_daty = sign_refl["SPAD"]
            keyw_data[str(coun_grop)] = {
                "comp_datx": func_rezu,
                "comp_daty": comp_daty
                }
        spli_data = self.create_data_splits(keyw_data)
        return spli_data

    def run(self):
        dict_spli_data = {}
        for func_name in self.func_data.keys():
            func_data = self.compute_singel_vegetation_indices(func_name)
            dict_spli_data[func_name] = func_data
        return dict_spli_data


if __name__ == "__main__":
    AutoDataModelTrainerCore().run()
